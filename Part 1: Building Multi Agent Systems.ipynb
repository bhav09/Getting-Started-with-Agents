{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63e41b8",
   "metadata": {},
   "source": [
    "# ADK (Agent Development Kit) Tutorial - How to Build Agentic Systems with Gemini Models\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook demonstrates using Google's ADK (Agent Development Kit) with Gemini models. You have two options for authentication:\n",
    "\n",
    "### Option 1: Google AI Studio (Gemini API Key)\n",
    "\n",
    "For personal projects, experiments, or if you don't have a Google Cloud account:\n",
    "\n",
    "1. Go to [Google AI Studio](https://makersuite.google.com/)\n",
    "2. Create a free account or sign in with your Google account\n",
    "3. Navigate to \"Get API Key\" in the top right or via settings\n",
    "4. Generate a new API key\n",
    "5. Create a `.env` file in the same directory as this notebook with:\n",
    "   ```\n",
    "   GOOGLE_API_KEY=your_api_key_here\n",
    "   USE_VERTEX_AI=False\n",
    "   ```\n",
    "\n",
    "### Option 2: Vertex AI (Google Cloud)\n",
    "\n",
    "For production environments, enterprise use, or when you need additional features:\n",
    "\n",
    "1. Create a [Google Cloud account](https://cloud.google.com/) if you don't have one\n",
    "2. Create a new project or select an existing one\n",
    "3. Enable the Vertex AI API in your project\n",
    "4. Set up authentication:\n",
    "   - Create a service account and download the JSON key, or\n",
    "   - Use Google Cloud SDK for local development (`gcloud auth application-default login`)\n",
    "5. Create a `.env` file with:\n",
    "   ```\n",
    "   GOOGLE_CLOUD_PROJECT=your_project_id\n",
    "   GOOGLE_CLOUD_LOCATION=us-central1  # or your preferred region\n",
    "   USE_VERTEX_AI=True\n",
    "   ```\n",
    "\n",
    "### Which Option Should I Use?\n",
    "\n",
    "- **Use Google AI Studio API Key (Option 1) if:**\n",
    "  - You're just getting started/experimenting\n",
    "  - You don't have a Google Cloud account\n",
    "  - You want a simpler setup process\n",
    "  - You're working on a personal project\n",
    "\n",
    "- **Use Vertex AI (Option 2) if:**\n",
    "  - You need enterprise-grade security and compliance\n",
    "  - You require higher rate limits\n",
    "  - You're building for production deployment\n",
    "  - You need advanced Vertex AI features\n",
    "\n",
    "### Required Python Packages\n",
    "\n",
    "Install the required packages:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This notebook automatically detects your configuration based on the `USE_VERTEX_AI` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fbb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import warnings\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import vertexai\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8ed9d",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f813b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean setup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "load_dotenv()\n",
    "\n",
    "# Check if running in Vertex AI or AI Studio\n",
    "USE_VERTEX_AI = os.getenv(\"USE_VERTEX_AI\", \"False\").lower() == \"True\"\n",
    "MODEL_GEMINI_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "if USE_VERTEX_AI:\n",
    "    # Vertex AI setup\n",
    "    from vertexai import init as vertexai_init\n",
    "    from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "    PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
    "    LOCATION = os.environ[\"GOOGLE_CLOUD_LOCATION\"]\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
    "\n",
    "    vertexai_init(project=PROJECT_ID, location=LOCATION)\n",
    "    # model = GenerativeModel(MODEL_GEMINI_FLASH)\n",
    "else:\n",
    "    # AI Studio setup\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"GOOGLE_API_KEY environment variable is not set.\")\n",
    "\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf676ec6",
   "metadata": {},
   "source": [
    "### A Vanilla Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3070657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A Vanilla AI Agent\n",
    "simple_agent = Agent(\n",
    "    name=\"helpful_assistant\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"A friendly AI that answers questions\",\n",
    "    instruction=\"You are helpful and conversational. Keep answers concise.\",\n",
    "    tools=[]  # No tools yet, just conversation\n",
    ")\n",
    "\n",
    "# Setup session (think of it as conversation memory)\n",
    "session_service = InMemorySessionService()\n",
    "APP_NAME = \"my_first_app\"\n",
    "USER_ID = \"user_123\"\n",
    "SESSION_ID = \"chat_001\"\n",
    "\n",
    "# Create the session\n",
    "await session_service.create_session(\n",
    "    app_name=APP_NAME, \n",
    "    user_id=USER_ID, \n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "\n",
    "# Create runner (this handles the conversation)\n",
    "runner = Runner(\n",
    "    agent=simple_agent, \n",
    "    app_name=APP_NAME, \n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8928883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë You: Hello! What all things you can do for me?\n",
      "ü§ñ Agent: I can answer questions, provide summaries, generate creative content, and have conversations on a variety of topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test your agent:\n",
    "async def chat_with_agent(message):\n",
    "    \"\"\"Send a message and get response\"\"\"\n",
    "    print(f\"üßë You: {message}\")\n",
    "    \n",
    "    content = types.Content(\n",
    "        role=\"user\", \n",
    "        parts=[types.Part(text=message)]\n",
    "    )\n",
    "    \n",
    "    async for event in runner.run_async(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response() and event.content:\n",
    "            response = event.content.parts[0].text\n",
    "            print(f\"ü§ñ Agent: {response}\")\n",
    "            break\n",
    "\n",
    "# Try it out!\n",
    "await chat_with_agent(\"Hello! What all things you can do for me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500e6a3",
   "metadata": {},
   "source": [
    "### Adding Tool to Vanilla Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f665c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë You: What's the latest breakthrough in AI research?\n",
      "üîç Searching...\n",
      "ü§ñ Agent: AI research is rapidly advancing across many fields. Here are some of the latest breakthroughs:\n",
      "\n",
      "*   AI-Driven Scientific Discovery: AI is accelerating breakthroughs in various scientific fields, including supercomputing, weather forecasting, drug discovery, and sustainable materials. For example, Microsoft Research developed AI2BMD, an AI-driven protein simulation system that helps researchers explore biomolecular science problems with unprecedented speed and precision.\n",
      "*   Robotics and Haptics: Researchers have created a revolutionary robotic skin made from a flexible, low-cost gel material that brings machines closer to human-like touch by allowing them to feel heat, pain, and pressure. Additionally, a four-legged AI robot has been developed that can play badminton with humans, showcasing the potential for human-robot collaboration in sports and training.\n",
      "*   Quantum Computing Enhancement: Quantum computing has received a boost with the development of a more efficient way to create \"magic states,\" a key component for fault-tolerant quantum computing. Additionally, Chalmers engineers have built a pulse-driven qubit amplifier that's ten times more efficient and safeguards quantum states, which is key for better quantum computers.\n",
      "*   AI for Material Science: AI is contributing to material science by accelerating the discovery and design of new materials, optimizing existing ones, and improving manufacturing processes. AI Researchers have also found a way to cut cement's carbon footprint dramatically by redesigning its recipe.\n",
      "*   AI Model Advancements: AI models are becoming faster, more efficient, and capable of handling a broader range of tasks. Models with advanced reasoning capabilities can solve complex problems with logical steps similar to human thinking.\n",
      "*   AI in Healthcare: AI is enhancing diagnostics, treatment, and patient care in the healthcare sector. For instance, AI can now help clinicians diagnose Parkinson's disease and related conditions faster and more accurately. Also, AI models have achieved human-level accuracy in interpreting medical images, aiding in the early detection of diseases like cancer.\n",
      "*   Brain-Computer Interface: Australian researchers have developed a brain-computer interface (BCI) that uses AI to translate brain signals into words, converting imagined speech into readable text with over 70% accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.adk.tools import google_search\n",
    "\n",
    "# Create an agent with search powers\n",
    "search_agent = Agent(\n",
    "    name=\"search_assistant\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"AI assistant that can search the internet\",\n",
    "    instruction=\"\"\"You can search the internet for current information. \n",
    "    When users ask about recent events or current info, use google_search.\"\"\",\n",
    "    tools=[google_search]  # This is the only new line!\n",
    ")\n",
    "\n",
    "# Create new runner for search agent\n",
    "search_runner = Runner(\n",
    "    agent=search_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "\n",
    "async def search_chat(message):\n",
    "    \"\"\"Chat with search-enabled agent\"\"\"\n",
    "    print(f\"üßë You: {message}\")\n",
    "    print(\"üîç Searching...\")\n",
    "    \n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=message)])\n",
    "    \n",
    "    async for event in search_runner.run_async(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,   # Different session\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response() and event.content:\n",
    "            response = event.content.parts[0].text.replace(\"**\", \"\")\n",
    "            print(f\"ü§ñ Agent: {response}\")\n",
    "            break\n",
    "\n",
    "# Try searching for current events\n",
    "await search_chat(\"What's the latest breakthrough in AI research?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92cd50e",
   "metadata": {},
   "source": [
    "### Vision Agent with Tool Use - Understanding Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ececd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"Convert image to base64 for AI processing\"\"\"\n",
    "    return base64.b64encode(Path(image_path).read_bytes()).decode()\n",
    "\n",
    "# Create vision-enabled agent\n",
    "vision_agent = Agent(\n",
    "    name=\"vision_assistant\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"AI that can see and understand images\",\n",
    "    instruction=\"\"\"You can analyze images and answer questions about them. \n",
    "    Describe what you see clearly and answer any questions about the image.\"\"\",\n",
    "    tools=[google_search]  # Can also search if needed\n",
    ")\n",
    "\n",
    "vision_runner = Runner(\n",
    "    agent=vision_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d80cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßë You: What do you see in this image?\n",
      "ü§ñ Agent: The image shows two iPhones, presumably the iPhone 14 Pro or a similar model, in what appears to be a gold or bronze color. The phone on the left displays the rear side, featuring a triple-lens camera system and the Apple logo. The phone on the right showcases the front side with the display on, which has a dark abstract wallpaper with orange accents. The overall presentation of the image suggests it is for promotional or display purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def chat_with_image(message, image_path=None, image_base64=None):\n",
    "    \"\"\"Send message with optional image\"\"\"\n",
    "    print(f\"üßë You: {message}\")\n",
    "\n",
    "    # Create message parts\n",
    "    parts = [types.Part(text=message)]\n",
    "    \n",
    "    # Add image if provided\n",
    "    if image_path:\n",
    "        data = Path(image_path).read_bytes()\n",
    "        mime_type = \"image/jpeg\" if image_path.endswith(('.jpg', '.jpeg')) else \"image/png\"\n",
    "        parts.append(types.Part.from_bytes(data=data, mime_type=mime_type))\n",
    "    elif image_base64:\n",
    "        data = base64.b64decode(image_base64)\n",
    "        parts.append(types.Part.from_bytes(data=data, mime_type=\"image/jpeg\"))\n",
    "\n",
    "    content = types.Content(role=\"user\", parts=parts)\n",
    "\n",
    "    async for event in vision_runner.run_async(\n",
    "        user_id=USER_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response() and event.content:\n",
    "            response = event.content.parts[0].text.replace(\"**\", \"\")\n",
    "            print(f\"ü§ñ Agent: {response}\")\n",
    "            break\n",
    "        \n",
    "await chat_with_image(\"What do you see in this image?\", image_path=\"images/image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9cac1",
   "metadata": {},
   "source": [
    "### Multi Modal - Multi Agent System with Custom Tool Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96fa963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom tool added!\n",
      "üßë You: What game is this, how old is it, and what's the latest news?\n",
      "üì∏ Processing image...\n",
      "üé¨ Pop Culture Expert: The game in the image is Super Mario Bros., which was released on September 13, 1985, making it almost 40 years old. While the exact North American release date is disputed, Nintendo officially recognizes it as October 18, 1985.\n",
      "\n",
      "Here's some of the latest news in the world of Super Mario:\n",
      "*   New Games: There are several new Mario games either recently released or coming soon, including Donkey Kong Bananza, Super Mario Party Jamboree, Mario Kart World, and Mario & Luigi: Brothership.\n",
      "*   Super Mario Bros. Wonder: Released in October 2023 for the Nintendo Switch, Super Mario Bros. Wonder has sold over 16 million copies as of March 31, 2025.\n",
      "*   New Super Mario Bros. U Deluxe: A Switch 2 update of New Super Mario Bros. U Deluxe has been released.\n",
      "\n",
      "üîß Tool used: 40 years have passed since 1985\n",
      "üé¨ Pop Culture Expert: Released 40 years ago in 1985.\n",
      "\n",
      "üé¨ Pop Culture Expert: The game in the image is Super Mario Bros., which was released 40 years ago in 1985. Here's some recent news in the world of Super Mario:\n",
      "\n",
      "*   New Games: There are several new Mario games either recently released or coming soon, including Donkey Kong Bananza, Super Mario Party Jamboree, Mario Kart World, and Mario & Luigi: Brothership.\n",
      "*   Super Mario Bros. Wonder: Released in October 2023 for the Nintendo Switch, Super Mario Bros. Wonder has sold over 16 million copies as of March 31, 2025.\n",
      "*   New Super Mario Bros. U Deluxe: A Switch 2 update of New Super Mario Bros. U Deluxe has been released.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "\n",
    "USER_ID = \"user_001\"\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "def years_since(year: int) -> int:\n",
    "    \"\"\"Calculate how many years have passed since a given year\"\"\"\n",
    "    today = date.today()\n",
    "    years_passed = today.year - year\n",
    "    print(f\"üîß Tool used: {years_passed} years have passed since {year}\")\n",
    "    return years_passed\n",
    "\n",
    "print(\"‚úÖ Custom tool added!\")\n",
    "\n",
    "async def chat_with_expert(message, image_path=None):\n",
    "    \"\"\"Chat function to interact with the expert system\"\"\"\n",
    "    \n",
    "    session_id = f\"multimodal_{USER_ID}_{int(time.time())}\"\n",
    "    await session_service.create_session(\n",
    "        app_name=\"entertainment_app\",\n",
    "        user_id=USER_ID,\n",
    "        session_id=session_id\n",
    "    )\n",
    "\n",
    "    print(f\"üßë You: {message}\")\n",
    "    parts = [types.Part(text=message)]\n",
    "\n",
    "    if image_path:\n",
    "        try:\n",
    "            image_file = Path(image_path)\n",
    "            if image_file.exists():\n",
    "                print(\"üì∏ Processing image...\")\n",
    "                data = image_file.read_bytes()\n",
    "                if image_path.lower().endswith(('.jpg', '.jpeg')):\n",
    "                    mime_type = \"image/jpeg\"\n",
    "                elif image_path.lower().endswith('.png'):\n",
    "                    mime_type = \"image/png\"\n",
    "                elif image_path.lower().endswith('.webp'):\n",
    "                    mime_type = \"image/webp\"\n",
    "                else:\n",
    "                    mime_type = \"image/jpeg\"\n",
    "                parts.append(types.Part.from_bytes(data=data, mime_type=mime_type))\n",
    "            else:\n",
    "                print(f\"‚ùå Image file not found: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading image: {e}\")\n",
    "    \n",
    "    content = types.Content(role=\"user\", parts=parts)\n",
    "\n",
    "    try:\n",
    "        async for event in expert_runner.run_async(\n",
    "            user_id=USER_ID,\n",
    "            session_id=session_id,\n",
    "            new_message=content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                response = event.content.parts[0].text.replace(\"**\", \"\")\n",
    "                print(f\"üé¨ Pop Culture Expert: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# === Step 2: Define Sub-Agents ===\n",
    "\n",
    "image_identifier = Agent(\n",
    "    name=\"image_identifier\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"Identify content from image\",\n",
    "    instruction=\"Identify the game, movie, or TV show in the image. Return only the title and when was it released using google_search tool\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "age_calculator = Agent(\n",
    "    name=\"age_calculator\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"Calculate how long ago the content was released years_since tool\",\n",
    "    instruction=\"Take the title, the date of release and calculate its release year and age. Format: 'Released X years ago in YYYY'\",\n",
    "    tools=[years_since]\n",
    ")\n",
    "\n",
    "news_searcher = Agent(\n",
    "    name=\"news_searcher\",\n",
    "    model=MODEL_GEMINI_FLASH,\n",
    "    description=\"Search for recent news about the title\",\n",
    "    instruction=\"Use the title to find 2-3 recent news updates.\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "# === Step 3: Define Fixed Sequential Agent ===\n",
    "\n",
    "class SequentialEntertainmentExpert(SequentialAgent):\n",
    "    async def run(self, user_id, session_id, new_message):\n",
    "        # Step 1: Identify title\n",
    "        step1 = await self.sub_agents[0].run(user_id=user_id, session_id=session_id, new_message=new_message)\n",
    "        title = step1.final_response.text.strip()\n",
    "        print(f\"üîç Detected title: {title}\")\n",
    "\n",
    "        # Step 2: Calculate age\n",
    "        age_msg = types.Content(role=\"user\", parts=[types.Part(text=title)])\n",
    "        step2 = await self.sub_agents[1].run(user_id=user_id, session_id=session_id, new_message=age_msg)\n",
    "        age_info = step2.final_response.text.strip()\n",
    "        print(f\"üìÖ Age Info: {age_info}\")\n",
    "\n",
    "        # Step 3: Get news\n",
    "        news_msg = types.Content(role=\"user\", parts=[types.Part(text=title)])\n",
    "        step3 = await self.sub_agents[2].run(user_id=user_id, session_id=session_id, new_message=news_msg)\n",
    "        news_info = step3.final_response.text.strip()\n",
    "        print(f\"üóûÔ∏è News Info: {news_info}\")\n",
    "\n",
    "        # Combine all\n",
    "        summary = f\"This is **{title}**. {age_info}. Recent news: {news_info}\"\n",
    "        return types.Response(content=types.Content(role=\"assistant\", parts=[types.Part(text=summary)]))\n",
    "\n",
    "# === Step 4: Create Runner ===\n",
    "\n",
    "def create_sequential_multimodal_fixed():\n",
    "    fixed_sequential_agent = SequentialEntertainmentExpert(\n",
    "        name=\"sequential_entertainment_expert_fixed\",\n",
    "        description=\"Sequential agent with explicit chaining\",\n",
    "        sub_agents=[image_identifier, age_calculator, news_searcher]\n",
    "    )\n",
    "\n",
    "    return Runner(\n",
    "        agent=fixed_sequential_agent,\n",
    "        app_name=\"entertainment_app\",\n",
    "        session_service=session_service\n",
    "    )\n",
    "\n",
    "# Assign fixed runner globally\n",
    "expert_runner = create_sequential_multimodal_fixed()\n",
    "\n",
    "# === Step 5: Run Test ===\n",
    "await chat_with_expert(\n",
    "        \"What game is this, how old is it, and what's the latest news?\",\n",
    "        \"images/mario.jpg\"  # Ensure this image exists locally\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d72f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
